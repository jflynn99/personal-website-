---
title: "Lessons Learned Building AI-Powered Products"
date: "2026-01-15"
description: "Key insights from integrating large language models into production applications, and the pitfalls to avoid."
tags:
  - AI
  - Product Management
  - Engineering
---

After spending the past year working on AI-powered features, I've accumulated a set of hard-won lessons that I wish someone had shared with me earlier.

## Start with the Problem, Not the Technology

It's tempting to start with "we should use AI for this" and work backwards. But the most successful AI features I've shipped started with a clear user problem, and AI happened to be the best solution.

Ask yourself: would users notice if you swapped out the AI for a rule-based system that achieved 80% of the same results? If not, you might be over-engineering.

## Latency is a Feature

Users have different expectations for AI interactions than traditional software. They'll tolerate a loading spinner for a "thinking" AI in ways they won't for a database query. But there's still a limit.

We found that streaming responses dramatically improved perceived performance, even when total time-to-completion was unchanged. Show users *something* is happening.

## The Eval Problem is Real

You can't improve what you can't measure. But measuring AI output quality is genuinely hard:

- **Automated evals** catch regressions but miss nuance
- **Human evals** are expensive and slow
- **User feedback** is biased toward extreme cases

The best approach I've found is a combination: automated evals for guardrails, periodic human review for calibration, and careful analysis of user feedback patterns.

## Prompt Engineering is Product Work

Your prompts are part of your product. They deserve the same rigor as your UI copy:

- Version control them
- A/B test significant changes
- Document the reasoning behind key decisions
- Review them in PRs like you would code

## Plan for Failure Modes

AI will fail. Sometimes spectacularly. Your job is to ensure failures are:

1. **Detectable** - You know when something went wrong
2. **Graceful** - Users aren't left stranded
3. **Recoverable** - There's a path forward

We built fallback flows for every AI feature. When the model fails or returns garbage, users see a helpful message and an alternative path, not an error screen.

## What's Next

I'm continuing to explore this space and will share more specific technical implementations in future posts. If you're building AI products and want to chat, feel free to reach out.
